{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roboflow Detection Plate - TFLite Object Detection.ipynb\n",
    "\n",
    "Adapted from the official Roboflow TFLite training notebook.\n",
    "This notebook trains a MobileNetSSDv2 model for license plate detection optimized for mobile devices.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this notebook, we use TensorFlow Lite to prepare a custom model on the \n",
    "DetectionPlate dataset for low-end (e.g. mobile) devices. It takes three steps:\n",
    "\n",
    "1. Import our dataset from Roboflow using the roboflow library\n",
    "2. Train a TensorFlow2 Object Detection Model (MobileNetSSDv2 - optimized for mobile)\n",
    "3. Convert the model to TensorFlow Lite\n",
    "\n",
    "## Workflow\n",
    "\n",
    "This model detects and classifies license plates in images:\n",
    "1. **Detection**: Locates the license plate in the image (returns bounding box coordinates)\n",
    "2. **Classification**: Identifies the plate type:\n",
    "   - 1: placa carro (old car plate)\n",
    "   - 2: placa carro mercosul (Mercosul car plate)\n",
    "   - 3: placa moto (old motorcycle plate)\n",
    "   - 4: placa moto mercosul (Mercosul motorcycle plate)\n",
    "3. **Output**: Returns coordinates (x, y, width, height) for cropping\n",
    "4. **Next Step**: Crop the detected region and send to a classification model for further processing\n",
    "\n",
    "Dataset: DetectionPlate (olhodeaguia/detectionplate-soevy v11)\n",
    "Format: COCO JSON (_annotations.coco.json)\n",
    "Resolution: 192x192 pixels\n",
    "Model: MobileNetSSDv2 (lightweight, optimized for mobile/edge devices)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8c44e",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 1: IMPORT AND PREPARE DATA\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22299b0f",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "Download dataset from Roboflow (COCO Format)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[1/3] Downloading dataset from Roboflow...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install roboflow library\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"roboflow\", \"-q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ef803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=\"SDfnuMydLG5k2Nq7dlny\")\n",
    "project = rf.workspace(\"olhodeaguia\").project(\"detectionplate-soevy\")\n",
    "version = project.version(11)  # Version 11 with COCO format (192x192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset in COCO format\n",
    "dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02479a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e7a5a",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "Prepare directory structure (following standard pattern)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8229b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create /content/train and /content/valid directories (Colab standard)\n",
    "os.makedirs(\"/content/train\", exist_ok=True)\n",
    "os.makedirs(\"/content/valid\", exist_ok=True)\n",
    "os.makedirs(\"/content/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08577d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset to standard locations\n",
    "train_src = os.path.join(dataset.location, \"train\")\n",
    "valid_src = os.path.join(dataset.location, \"valid\")\n",
    "test_src = os.path.join(dataset.location, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10819cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train data\n",
    "if os.path.exists(train_src):\n",
    "    for item in os.listdir(train_src):\n",
    "        src = os.path.join(train_src, item)\n",
    "        dst = os.path.join(\"/content/train\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Train data copied to /content/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy valid data\n",
    "if os.path.exists(valid_src):\n",
    "    for item in os.listdir(valid_src):\n",
    "        src = os.path.join(valid_src, item)\n",
    "        dst = os.path.join(\"/content/valid\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Valid data copied to /content/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy test data\n",
    "if os.path.exists(test_src):\n",
    "    for item in os.listdir(test_src):\n",
    "        src = os.path.join(test_src, item)\n",
    "        dst = os.path.join(\"/content/test\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Test data copied to /content/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify directories exist\n",
    "train_dir = \"/content/train\"\n",
    "valid_dir = \"/content/valid\"\n",
    "test_dir = \"/content/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e355309",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(train_dir), f\"Train directory not found: {train_dir}\"\n",
    "assert os.path.exists(valid_dir), f\"Valid directory not found: {valid_dir}\"\n",
    "assert os.path.exists(test_dir), f\"Test directory not found: {test_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images\n",
    "train_images = len(os.listdir(os.path.join(train_dir, 'images'))) if os.path.exists(os.path.join(train_dir, 'images')) else 0\n",
    "valid_images = len(os.listdir(os.path.join(valid_dir, 'images'))) if os.path.exists(os.path.join(valid_dir, 'images')) else 0\n",
    "test_images = len(os.listdir(os.path.join(test_dir, 'images'))) if os.path.exists(os.path.join(test_dir, 'images')) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ef7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Train images: {train_images}\")\n",
    "print(f\"  Valid images: {valid_images}\")\n",
    "print(f\"  Test images: {test_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b72d68",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 2: SETUP TENSORFLOW OBJECT DETECTION API\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14530a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2/3] Setting up TensorFlow Object Detection API...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone tensorflow models repository\n",
    "if not os.path.exists(\"models\"):\n",
    "    print(\"Cloning TensorFlow models repository...\")\n",
    "    os.system(\"git clone --quiet https://github.com/tensorflow/models.git\")\n",
    "else:\n",
    "    print(\"Models repository already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing required packages...\")\n",
    "os.system(\"pip install -q tf_slim\")\n",
    "os.system(\"apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\")\n",
    "os.system(\"pip install -q Cython contextlib2 pillow lxml matplotlib\")\n",
    "os.system(\"pip install -q pycocotools\")\n",
    "os.system(\"pip install -q lvis==0.5.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd42955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile protobuf files\n",
    "print(\"Compiling protobuf files...\")\n",
    "os.chdir(\"models/research\")\n",
    "os.system(\"protoc object_detection/protos/*.proto --python_out=.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Python path\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the installation\n",
    "print(\"Testing TensorFlow Object Detection API installation...\")\n",
    "os.system(\"python object_detection/builders/model_builder_test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7053f6",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 3: PREPARE DATA DIRECTORY FOR TRAINING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3/3] Preparing data directory for training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory structure (following standard pattern)\n",
    "data_dir = \"/content/tensorflow-object-detection-faster-rcnn/data\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train and valid data to data directory\n",
    "train_data_dir = os.path.join(data_dir, \"train\")\n",
    "valid_data_dir = os.path.join(data_dir, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57828c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(valid_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from /content/train to data directory\n",
    "if os.path.exists(os.path.join(\"/content/train\", \"images\")):\n",
    "    shutil.copytree(os.path.join(\"/content/train\", \"images\"), \n",
    "                    os.path.join(train_data_dir, \"images\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Train images copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/train\", \"labels\")):\n",
    "    shutil.copytree(os.path.join(\"/content/train\", \"labels\"), \n",
    "                    os.path.join(train_data_dir, \"labels\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Train labels copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ac0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/train\", \"_annotations.coco.json\")):\n",
    "    shutil.copy(os.path.join(\"/content/train\", \"_annotations.coco.json\"),\n",
    "               os.path.join(train_data_dir, \"_annotations.coco.json\"))\n",
    "    print(f\"✓ Train annotations copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from /content/valid to data directory\n",
    "if os.path.exists(os.path.join(\"/content/valid\", \"images\")):\n",
    "    shutil.copytree(os.path.join(\"/content/valid\", \"images\"), \n",
    "                    os.path.join(valid_data_dir, \"images\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Valid images copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/valid\", \"labels\")):\n",
    "    shutil.copytree(os.path.join(\"/content/valid\", \"labels\"), \n",
    "                    os.path.join(valid_data_dir, \"labels\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Valid labels copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/valid\", \"_annotations.coco.json\")):\n",
    "    shutil.copy(os.path.join(\"/content/valid\", \"_annotations.coco.json\"),\n",
    "               os.path.join(valid_data_dir, \"_annotations.coco.json\"))\n",
    "    print(f\"✓ Valid annotations copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4213b96",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 4: CONFIGURE MODEL AND TRAINING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfiguring model for training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d100eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'ssd_mobilenet_v2'\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf466aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_steps = 100000  # Increase for better accuracy\n",
    "num_eval_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7771e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training steps: {num_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d6619",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 5: DOWNLOAD AND PREPARE BASE MODEL\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDownloading pre-trained base model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = 'pretrained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_FILE):\n",
    "    print(f\"Downloading {MODEL_FILE}...\")\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(MODEL_FILE)\n",
    "if os.path.exists(DEST_DIR):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb175d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "print(f\"Fine-tune checkpoint: {fine_tune_checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e8aeb",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 6: CREATE LABEL MAP (COCO Format - Named Classes)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating label map file (COCO format with named classes)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes from COCO format - IDs 1-4 (ID 0 is reserved for \"plates\" supercategory)\n",
    "classes = {\n",
    "    1: 'placa carro',\n",
    "    2: 'placa carro mercosul',\n",
    "    3: 'placa moto',\n",
    "    4: 'placa moto mercosul'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d06c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label map in TensorFlow format (matching COCO IDs)\n",
    "label_map_content = \"\"\n",
    "for class_id, class_name in classes.items():\n",
    "    label_map_content += f\"\"\"item {{\n",
    "  id: {class_id}\n",
    "  name: '{class_name}'\n",
    "}}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = os.path.join(data_dir, \"label_map.pbtxt\")\n",
    "with open(label_map_path, 'w') as f:\n",
    "    f.write(label_map_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ad092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create COCO format names file (one class per line, indexed by ID)\n",
    "coco_names_path = os.path.join(data_dir, \"classes.names\")\n",
    "with open(coco_names_path, 'w') as f:\n",
    "    for class_id in sorted(classes.keys()):\n",
    "        f.write(f\"{class_id}: {classes[class_id]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41697ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✓ Label map created: {label_map_path}\")\n",
    "print(f\"✓ COCO classes file created: {coco_names_path}\")\n",
    "print(f\"✓ Classes ({len(classes)} total):\")\n",
    "for class_id, class_name in classes.items():\n",
    "    print(f\"    {class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5c4f1",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 7: CONFIGURE TRAINING PIPELINE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e210712",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfiguring training pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = os.path.join('models/research/object_detection/samples/configs/', pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(pipeline_fname), f'Pipeline file not found: {pipeline_fname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2967849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c01a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and modify pipeline configuration\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d541cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_fname, 'w') as f:\n",
    "    # Set fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
    "    \n",
    "    # Set training record file\n",
    "    train_record = os.path.join(os.path.abspath(data_dir), \"train\", \"train.record\")\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', \n",
    "        f'input_path: \"{train_record}\"', s)\n",
    "    \n",
    "    # Set validation record file\n",
    "    val_record = os.path.join(os.path.abspath(data_dir), \"valid\", \"val.record\")\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', \n",
    "        f'input_path: \"{val_record}\"', s)\n",
    "    \n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', \n",
    "        f'label_map_path: \"{label_map_path}\"', s)\n",
    "    \n",
    "    # Set training batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               f'batch_size: {batch_size}', s)\n",
    "    \n",
    "    # Set training steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               f'num_steps: {num_steps}', s)\n",
    "    \n",
    "    # Set number of classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               f'num_classes: {num_classes}', s)\n",
    "    \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pipeline configured with {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2448622",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 8: TRAIN THE MODEL\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "print(\"This may take a while depending on the number of steps and GPU availability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8895791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/content/tensorflow-object-detection-faster-rcnn/training/'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_command = (\n",
    "    f\"python object_detection/model_main.py \"\n",
    "    f\"--pipeline_config_path={pipeline_fname} \"\n",
    "    f\"--model_dir={model_dir} \"\n",
    "    f\"--alsologtostderr \"\n",
    "    f\"--num_train_steps={num_steps} \"\n",
    "    f\"--num_eval_steps={num_eval_steps}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5006e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running: {train_command}\")\n",
    "os.system(train_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8c752",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 9: EXPORT TRAINED MODEL FOR TFLITE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9655820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExporting trained model for TFLite conversion...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = './fine_tuned_model'\n",
    "tflite_directory = './fine_tuned_model/tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "if not os.path.exists(model_dir):\n",
    "    print(f\"❌ Model directory not found: {model_dir}\")\n",
    "    print(\"Training may not have completed successfully.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9be5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lst:\n",
    "    print(f\"✓ Found {len(lst)} checkpoints\")\n",
    "    steps = np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "    last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "    last_model_path = os.path.join(model_dir, last_model)\n",
    "    \n",
    "    print(f\"Using checkpoint: {last_model_path}\")\n",
    "    \n",
    "    # Export inference graph\n",
    "    export_command = (\n",
    "        f\"python object_detection/export_inference_graph.py \"\n",
    "        f\"--input_type=image_tensor \"\n",
    "        f\"--pipeline_config_path={pipeline_fname} \"\n",
    "        f\"--output_directory={output_directory} \"\n",
    "        f\"--trained_checkpoint_prefix={last_model_path}\"\n",
    "    )\n",
    "    print(f\"Exporting inference graph...\")\n",
    "    os.system(export_command)\n",
    "    \n",
    "    # Export TFLite graph\n",
    "    export_tflite_command = (\n",
    "        f\"python object_detection/export_tflite_ssd_graph.py \"\n",
    "        f\"--input_type=image_tensor \"\n",
    "        f\"--pipeline_config_path={pipeline_fname} \"\n",
    "        f\"--output_directory={tflite_directory} \"\n",
    "        f\"--trained_checkpoint_prefix={last_model_path}\"\n",
    "    )\n",
    "    print(f\"Exporting TFLite graph...\")\n",
    "    os.system(export_tflite_command)\n",
    "else:\n",
    "    print(\"No checkpoints found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab3584",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 10: CONVERT TO TFLITE WITH UINT8 QUANTIZATION AND RGB FORMAT\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConverting model to TensorFlow Lite format with UINT8 quantization...\")\n",
    "print(\"Format: RGB (3 channels)\")\n",
    "print(\"Quantization: UINT8 (8-bit unsigned integer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376672cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_graph_path = os.path.join('models/research/fine_tuned_model/tflite/tflite_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f56099",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(tflite_graph_path):\n",
    "    # Convert using TFLite converter with UINT8 quantization\n",
    "    convert_command = (\n",
    "        \"tflite_convert \"\n",
    "        \"--input_shape=1,192,192,3 \"\n",
    "        \"--input_arrays=normalized_input_image_tensor \"\n",
    "        \"--output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,\"\n",
    "        \"TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 \"\n",
    "        \"--allow_custom_ops \"\n",
    "        \"--inference_type=QUANTIZED_UINT8 \"\n",
    "        \"--inference_input_type=QUANTIZED_UINT8 \"\n",
    "        \"--mean_values=128 \"\n",
    "        \"--std_dev_values=128 \"\n",
    "        f\"--graph_def_file={tflite_graph_path} \"\n",
    "        \"--output_file=detection_plate_model.tflite\"\n",
    "    )\n",
    "    print(f\"Running TFLite conversion with UINT8 quantization...\")\n",
    "    os.system(convert_command)\n",
    "    \n",
    "    print(\"\\n✓ TFLite model successfully created: detection_plate_model.tflite\")\n",
    "    print(\"  - Quantization: UINT8 (8-bit)\")\n",
    "    print(\"  - Format: RGB (3 channels)\")\n",
    "    print(\"  - Input size: 192x192 (COCO format)\")\n",
    "    print(\"  - Optimized for mobile/edge devices\")\n",
    "else:\n",
    "    print(f\"TFLite graph not found at {tflite_graph_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731c173",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 11: TEST INFERENCE (OPTIONAL)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTesting inference on sample images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = os.path.join(dataset.location, \"test\", \"images\")\n",
    "test_images = glob.glob(os.path.join(test_images_dir, \"*.*\"))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a23bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_images:\n",
    "    print(f\"Found {len(test_images)} test images\")\n",
    "    for img_path in test_images:\n",
    "        print(f\"  - {os.path.basename(img_path)}\")\n",
    "else:\n",
    "    print(\"No test images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"TFLite model saved as: detection_plate_model.tflite\")\n",
    "print(f\"Model directory: {os.path.abspath('models/research/fine_tuned_model')}\")\n",
    "print(\"\\nClasses (YOLO format - Named):\")\n",
    "for idx, class_name in enumerate(classes):\n",
    "    print(f\"  {idx}: {class_name}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a788b7e",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 12: INFERENCE EXAMPLE WITH CROP\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFERENCE EXAMPLE - How to use the model\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_code = \"\"\"\n",
    "# Example: Using the trained TFLite model for inference with crop\n",
    "# Model: UINT8 quantized, RGB format\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load TFLite model (UINT8 quantized)\n",
    "interpreter = tf.lite.Interpreter(model_path='detection_plate_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('test_image.jpg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Resize to model input size (192x192 for DetectionPlate COCO format)\n",
    "input_size = 192\n",
    "resized_image = cv2.resize(image_rgb, (input_size, input_size))\n",
    "\n",
    "# Prepare input for UINT8 quantized model\n",
    "# Input range: 0-255 (UINT8)\n",
    "input_data = np.expand_dims(resized_image, axis=0).astype(np.uint8)\n",
    "\n",
    "# Run inference\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get detections\n",
    "detections = interpreter.get_tensor(output_details[0]['index'])\n",
    "detection_classes = interpreter.get_tensor(output_details[1]['index'])\n",
    "detection_scores = interpreter.get_tensor(output_details[2]['index'])\n",
    "\n",
    "# Process detections (COCO format - IDs 1-4)\n",
    "class_names = {\n",
    "    1: 'placa carro',\n",
    "    2: 'placa carro mercosul',\n",
    "    3: 'placa moto',\n",
    "    4: 'placa moto mercosul'\n",
    "}\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "for i in range(len(detection_scores[0])):\n",
    "    score = detection_scores[0][i]\n",
    "    if score > confidence_threshold:\n",
    "        # Get bounding box coordinates (normalized 0-1)\n",
    "        box = detections[0][i]\n",
    "        y_min, x_min, y_max, x_max = box\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        x_min_px = int(x_min * width)\n",
    "        y_min_px = int(y_min * height)\n",
    "        x_max_px = int(x_max * width)\n",
    "        y_max_px = int(y_max * height)\n",
    "        \n",
    "        # Get class (COCO format - IDs 1-4)\n",
    "        class_id = int(detection_classes[0][i])\n",
    "        class_name = class_names.get(class_id, f'Unknown ({class_id})')\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(image, (x_min_px, y_min_px), (x_max_px, y_max_px), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{class_name} ({score:.2f})', \n",
    "                   (x_min_px, y_min_px - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # CROP the detected plate region\n",
    "        cropped_plate = image[y_min_px:y_max_px, x_min_px:x_max_px]\n",
    "        \n",
    "        # Save or process the cropped plate\n",
    "        # cv2.imwrite(f'plate_{class_name}_{i}.jpg', cropped_plate)\n",
    "        # Send cropped_plate to classification model for further processing\n",
    "\n",
    "# Display result\n",
    "cv2.imshow('Detections', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference_code)\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
