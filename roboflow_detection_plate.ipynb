{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roboflow Detection Plate - TFLite Object Detection.ipynb\n",
    "\n",
    "Adapted from the official Roboflow TFLite training notebook.\n",
    "This notebook trains a MobileNetSSDv2 model for license plate detection optimized for mobile devices.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this notebook, we use TensorFlow Lite to prepare a custom model on the \n",
    "DetectionPlate dataset for low-end (e.g. mobile) devices. It takes three steps:\n",
    "\n",
    "1. Import our dataset from Roboflow using the roboflow library\n",
    "2. Train a TensorFlow2 Object Detection Model (MobileNetSSDv2 - optimized for mobile)\n",
    "3. Convert the model to TensorFlow Lite\n",
    "\n",
    "## Workflow\n",
    "\n",
    "This model detects and classifies license plates in images:\n",
    "1. **Detection**: Locates the license plate in the image (returns bounding box coordinates)\n",
    "2. **Classification**: Identifies the plate type:\n",
    "   - 1: placa carro (old car plate)\n",
    "   - 2: placa carro mercosul (Mercosul car plate)\n",
    "   - 3: placa moto (old motorcycle plate)\n",
    "   - 4: placa moto mercosul (Mercosul motorcycle plate)\n",
    "3. **Output**: Returns coordinates (x, y, width, height) for cropping\n",
    "4. **Next Step**: Crop the detected region and send to a classification model for further processing\n",
    "\n",
    "Dataset: DetectionPlate (olhodeaguia/detectionplate-soevy v11)\n",
    "Format: COCO JSON (_annotations.coco.json)\n",
    "Resolution: 192x192 pixels\n",
    "Model: MobileNetSSDv2 (lightweight, optimized for mobile/edge devices)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fac76e",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 1: IMPORT AND PREPARE DATA\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d09be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d87e21",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "Download dataset from Roboflow (COCO Format)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[1/3] Downloading dataset from Roboflow...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install roboflow library\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"roboflow\", \"-q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=\"SDfnuMydLG5k2Nq7dlny\")\n",
    "project = rf.workspace(\"olhodeaguia\").project(\"detectionplate-soevy\")\n",
    "version = project.version(11)  # Version 11 with COCO format (192x192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2408ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset in COCO format\n",
    "dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84072067",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "Prepare directory structure (following standard pattern)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac04e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create /content/train and /content/valid directories (Colab standard)\n",
    "os.makedirs(\"/content/train\", exist_ok=True)\n",
    "os.makedirs(\"/content/valid\", exist_ok=True)\n",
    "os.makedirs(\"/content/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84046451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset to standard locations\n",
    "train_src = os.path.join(dataset.location, \"train\")\n",
    "valid_src = os.path.join(dataset.location, \"valid\")\n",
    "test_src = os.path.join(dataset.location, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train data\n",
    "if os.path.exists(train_src):\n",
    "    for item in os.listdir(train_src):\n",
    "        src = os.path.join(train_src, item)\n",
    "        dst = os.path.join(\"/content/train\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Train data copied to /content/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy valid data\n",
    "if os.path.exists(valid_src):\n",
    "    for item in os.listdir(valid_src):\n",
    "        src = os.path.join(valid_src, item)\n",
    "        dst = os.path.join(\"/content/valid\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Valid data copied to /content/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy test data\n",
    "if os.path.exists(test_src):\n",
    "    for item in os.listdir(test_src):\n",
    "        src = os.path.join(test_src, item)\n",
    "        dst = os.path.join(\"/content/test\", item)\n",
    "        if os.path.isdir(src):\n",
    "            shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"✓ Test data copied to /content/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify directories exist\n",
    "train_dir = \"/content/train\"\n",
    "valid_dir = \"/content/valid\"\n",
    "test_dir = \"/content/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a396a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(train_dir), f\"Train directory not found: {train_dir}\"\n",
    "assert os.path.exists(valid_dir), f\"Valid directory not found: {valid_dir}\"\n",
    "assert os.path.exists(test_dir), f\"Test directory not found: {test_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ef4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images\n",
    "train_images = len(os.listdir(os.path.join(train_dir, 'images'))) if os.path.exists(os.path.join(train_dir, 'images')) else 0\n",
    "valid_images = len(os.listdir(os.path.join(valid_dir, 'images'))) if os.path.exists(os.path.join(valid_dir, 'images')) else 0\n",
    "test_images = len(os.listdir(os.path.join(test_dir, 'images'))) if os.path.exists(os.path.join(test_dir, 'images')) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Train images: {train_images}\")\n",
    "print(f\"  Valid images: {valid_images}\")\n",
    "print(f\"  Test images: {test_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7b973",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 2: SETUP TENSORFLOW OBJECT DETECTION API\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2/3] Setting up TensorFlow Object Detection API...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75411f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone tensorflow models repository\n",
    "if not os.path.exists(\"models\"):\n",
    "    print(\"Cloning TensorFlow models repository...\")\n",
    "    os.system(\"git clone --quiet https://github.com/tensorflow/models.git\")\n",
    "else:\n",
    "    print(\"Models repository already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing required packages...\")\n",
    "os.system(\"pip install -q tf_slim\")\n",
    "os.system(\"apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\")\n",
    "os.system(\"pip install -q Cython contextlib2 pillow lxml matplotlib\")\n",
    "os.system(\"pip install -q pycocotools\")\n",
    "os.system(\"pip install -q lvis==0.5.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd181c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile protobuf files\n",
    "print(\"Compiling protobuf files...\")\n",
    "os.chdir(\"models/research\")\n",
    "os.system(\"protoc object_detection/protos/*.proto --python_out=.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Python path\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8720df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the installation\n",
    "print(\"Testing TensorFlow Object Detection API installation...\")\n",
    "os.system(\"python object_detection/builders/model_builder_test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e090ff7",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 3: PREPARE DATA DIRECTORY FOR TRAINING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d811ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3/3] Preparing data directory for training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory structure (following standard pattern)\n",
    "data_dir = \"/content/tensorflow-object-detection-faster-rcnn/data\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d14b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train and valid data to data directory\n",
    "train_data_dir = os.path.join(data_dir, \"train\")\n",
    "valid_data_dir = os.path.join(data_dir, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(valid_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from /content/train to data directory\n",
    "if os.path.exists(os.path.join(\"/content/train\", \"images\")):\n",
    "    shutil.copytree(os.path.join(\"/content/train\", \"images\"), \n",
    "                    os.path.join(train_data_dir, \"images\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Train images copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9762021",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/train\", \"labels\")):\n",
    "    shutil.copytree(os.path.join(\"/content/train\", \"labels\"), \n",
    "                    os.path.join(train_data_dir, \"labels\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Train labels copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/train\", \"_annotations.coco.json\")):\n",
    "    shutil.copy(os.path.join(\"/content/train\", \"_annotations.coco.json\"),\n",
    "               os.path.join(train_data_dir, \"_annotations.coco.json\"))\n",
    "    print(f\"✓ Train annotations copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7863d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from /content/valid to data directory\n",
    "if os.path.exists(os.path.join(\"/content/valid\", \"images\")):\n",
    "    shutil.copytree(os.path.join(\"/content/valid\", \"images\"), \n",
    "                    os.path.join(valid_data_dir, \"images\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Valid images copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b73cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/valid\", \"labels\")):\n",
    "    shutil.copytree(os.path.join(\"/content/valid\", \"labels\"), \n",
    "                    os.path.join(valid_data_dir, \"labels\"), \n",
    "                    dirs_exist_ok=True)\n",
    "    print(f\"✓ Valid labels copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a20f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"/content/valid\", \"_annotations.coco.json\")):\n",
    "    shutil.copy(os.path.join(\"/content/valid\", \"_annotations.coco.json\"),\n",
    "               os.path.join(valid_data_dir, \"_annotations.coco.json\"))\n",
    "    print(f\"✓ Valid annotations copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850748f8",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 4: CONFIGURE MODEL AND TRAINING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfiguring model for training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0389a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'ssd_mobilenet_v2'\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77118b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_steps = 100000  # Increase for better accuracy\n",
    "num_eval_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training steps: {num_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d9996",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 5: DOWNLOAD AND PREPARE BASE MODEL\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDownloading pre-trained base model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = 'pretrained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_FILE):\n",
    "    print(f\"Downloading {MODEL_FILE}...\")\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(MODEL_FILE)\n",
    "if os.path.exists(DEST_DIR):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "print(f\"Fine-tune checkpoint: {fine_tune_checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044908b",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 6: CREATE LABEL MAP (COCO Format - Named Classes)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating label map file (COCO format with named classes)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes from COCO format - IDs 1-4 (ID 0 is reserved for \"plates\" supercategory)\n",
    "classes = {\n",
    "    1: 'placa carro',\n",
    "    2: 'placa carro mercosul',\n",
    "    3: 'placa moto',\n",
    "    4: 'placa moto mercosul'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label map in TensorFlow format (matching COCO IDs)\n",
    "label_map_content = \"\"\n",
    "for class_id, class_name in classes.items():\n",
    "    label_map_content += f\"\"\"item {{\n",
    "  id: {class_id}\n",
    "  name: '{class_name}'\n",
    "}}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6487dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = os.path.join(data_dir, \"label_map.pbtxt\")\n",
    "with open(label_map_path, 'w') as f:\n",
    "    f.write(label_map_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create COCO format names file (one class per line, indexed by ID)\n",
    "coco_names_path = os.path.join(data_dir, \"classes.names\")\n",
    "with open(coco_names_path, 'w') as f:\n",
    "    for class_id in sorted(classes.keys()):\n",
    "        f.write(f\"{class_id}: {classes[class_id]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✓ Label map created: {label_map_path}\")\n",
    "print(f\"✓ COCO classes file created: {coco_names_path}\")\n",
    "print(f\"✓ Classes ({len(classes)} total):\")\n",
    "for class_id, class_name in classes.items():\n",
    "    print(f\"    {class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab5486",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 7: CONFIGURE TRAINING PIPELINE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfiguring training pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = os.path.join('models/research/object_detection/samples/configs/', pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(pipeline_fname), f'Pipeline file not found: {pipeline_fname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1611537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and modify pipeline configuration\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_fname, 'w') as f:\n",
    "    # Set fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
    "    \n",
    "    # Set training record file\n",
    "    train_record = os.path.join(os.path.abspath(data_dir), \"train\", \"train.record\")\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', \n",
    "        f'input_path: \"{train_record}\"', s)\n",
    "    \n",
    "    # Set validation record file\n",
    "    val_record = os.path.join(os.path.abspath(data_dir), \"valid\", \"val.record\")\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', \n",
    "        f'input_path: \"{val_record}\"', s)\n",
    "    \n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', \n",
    "        f'label_map_path: \"{label_map_path}\"', s)\n",
    "    \n",
    "    # Set training batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               f'batch_size: {batch_size}', s)\n",
    "    \n",
    "    # Set training steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               f'num_steps: {num_steps}', s)\n",
    "    \n",
    "    # Set number of classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               f'num_classes: {num_classes}', s)\n",
    "    \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pipeline configured with {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b81b50",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 8: TRAIN THE MODEL\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "print(\"This may take a while depending on the number of steps and GPU availability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ee694",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_command = (\n",
    "    f\"python object_detection/model_main.py \"\n",
    "    f\"--pipeline_config_path={pipeline_fname} \"\n",
    "    f\"--model_dir={model_dir} \"\n",
    "    f\"--alsologtostderr \"\n",
    "    f\"--num_train_steps={num_steps} \"\n",
    "    f\"--num_eval_steps={num_eval_steps}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running: {train_command}\")\n",
    "os.system(train_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc4c2d",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 9: EXPORT TRAINED MODEL FOR TFLITE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17426db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExporting trained model for TFLite conversion...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ff411",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99658382",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = './fine_tuned_model'\n",
    "tflite_directory = './fine_tuned_model/tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95060291",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lst:\n",
    "    steps = np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "    last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "    last_model_path = os.path.join(model_dir, last_model)\n",
    "    \n",
    "    print(f\"Using checkpoint: {last_model_path}\")\n",
    "    \n",
    "    # Export inference graph\n",
    "    export_command = (\n",
    "        f\"python object_detection/export_inference_graph.py \"\n",
    "        f\"--input_type=image_tensor \"\n",
    "        f\"--pipeline_config_path={pipeline_fname} \"\n",
    "        f\"--output_directory={output_directory} \"\n",
    "        f\"--trained_checkpoint_prefix={last_model_path}\"\n",
    "    )\n",
    "    print(f\"Exporting inference graph...\")\n",
    "    os.system(export_command)\n",
    "    \n",
    "    # Export TFLite graph\n",
    "    export_tflite_command = (\n",
    "        f\"python object_detection/export_tflite_ssd_graph.py \"\n",
    "        f\"--input_type=image_tensor \"\n",
    "        f\"--pipeline_config_path={pipeline_fname} \"\n",
    "        f\"--output_directory={tflite_directory} \"\n",
    "        f\"--trained_checkpoint_prefix={last_model_path}\"\n",
    "    )\n",
    "    print(f\"Exporting TFLite graph...\")\n",
    "    os.system(export_tflite_command)\n",
    "else:\n",
    "    print(\"No checkpoints found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa7f0e",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 10: CONVERT TO TFLITE WITH UINT8 QUANTIZATION AND RGB FORMAT\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConverting model to TensorFlow Lite format with UINT8 quantization...\")\n",
    "print(\"Format: RGB (3 channels)\")\n",
    "print(\"Quantization: UINT8 (8-bit unsigned integer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_graph_path = os.path.join('models/research/fine_tuned_model/tflite/tflite_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(tflite_graph_path):\n",
    "    # Convert using TFLite converter with UINT8 quantization\n",
    "    convert_command = (\n",
    "        \"tflite_convert \"\n",
    "        \"--input_shape=1,192,192,3 \"\n",
    "        \"--input_arrays=normalized_input_image_tensor \"\n",
    "        \"--output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,\"\n",
    "        \"TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 \"\n",
    "        \"--allow_custom_ops \"\n",
    "        \"--inference_type=QUANTIZED_UINT8 \"\n",
    "        \"--inference_input_type=QUANTIZED_UINT8 \"\n",
    "        \"--mean_values=128 \"\n",
    "        \"--std_dev_values=128 \"\n",
    "        f\"--graph_def_file={tflite_graph_path} \"\n",
    "        \"--output_file=detection_plate_model.tflite\"\n",
    "    )\n",
    "    print(f\"Running TFLite conversion with UINT8 quantization...\")\n",
    "    os.system(convert_command)\n",
    "    \n",
    "    print(\"\\n✓ TFLite model successfully created: detection_plate_model.tflite\")\n",
    "    print(\"  - Quantization: UINT8 (8-bit)\")\n",
    "    print(\"  - Format: RGB (3 channels)\")\n",
    "    print(\"  - Input size: 192x192 (COCO format)\")\n",
    "    print(\"  - Optimized for mobile/edge devices\")\n",
    "else:\n",
    "    print(f\"TFLite graph not found at {tflite_graph_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111959a",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 11: TEST INFERENCE (OPTIONAL)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTesting inference on sample images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = os.path.join(dataset.location, \"test\", \"images\")\n",
    "test_images = glob.glob(os.path.join(test_images_dir, \"*.*\"))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e99010",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_images:\n",
    "    print(f\"Found {len(test_images)} test images\")\n",
    "    for img_path in test_images:\n",
    "        print(f\"  - {os.path.basename(img_path)}\")\n",
    "else:\n",
    "    print(\"No test images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"TFLite model saved as: detection_plate_model.tflite\")\n",
    "print(f\"Model directory: {os.path.abspath('models/research/fine_tuned_model')}\")\n",
    "print(\"\\nClasses (YOLO format - Named):\")\n",
    "for idx, class_name in enumerate(classes):\n",
    "    print(f\"  {idx}: {class_name}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46013280",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "STEP 12: INFERENCE EXAMPLE WITH CROP\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defccf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFERENCE EXAMPLE - How to use the model\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb878c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_code = \"\"\"\n",
    "# Example: Using the trained TFLite model for inference with crop\n",
    "# Model: UINT8 quantized, RGB format\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load TFLite model (UINT8 quantized)\n",
    "interpreter = tf.lite.Interpreter(model_path='detection_plate_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('test_image.jpg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Resize to model input size (192x192 for DetectionPlate COCO format)\n",
    "input_size = 192\n",
    "resized_image = cv2.resize(image_rgb, (input_size, input_size))\n",
    "\n",
    "# Prepare input for UINT8 quantized model\n",
    "# Input range: 0-255 (UINT8)\n",
    "input_data = np.expand_dims(resized_image, axis=0).astype(np.uint8)\n",
    "\n",
    "# Run inference\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get detections\n",
    "detections = interpreter.get_tensor(output_details[0]['index'])\n",
    "detection_classes = interpreter.get_tensor(output_details[1]['index'])\n",
    "detection_scores = interpreter.get_tensor(output_details[2]['index'])\n",
    "\n",
    "# Process detections (COCO format - IDs 1-4)\n",
    "class_names = {\n",
    "    1: 'placa carro',\n",
    "    2: 'placa carro mercosul',\n",
    "    3: 'placa moto',\n",
    "    4: 'placa moto mercosul'\n",
    "}\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "for i in range(len(detection_scores[0])):\n",
    "    score = detection_scores[0][i]\n",
    "    if score > confidence_threshold:\n",
    "        # Get bounding box coordinates (normalized 0-1)\n",
    "        box = detections[0][i]\n",
    "        y_min, x_min, y_max, x_max = box\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        x_min_px = int(x_min * width)\n",
    "        y_min_px = int(y_min * height)\n",
    "        x_max_px = int(x_max * width)\n",
    "        y_max_px = int(y_max * height)\n",
    "        \n",
    "        # Get class (COCO format - IDs 1-4)\n",
    "        class_id = int(detection_classes[0][i])\n",
    "        class_name = class_names.get(class_id, f'Unknown ({class_id})')\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(image, (x_min_px, y_min_px), (x_max_px, y_max_px), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{class_name} ({score:.2f})', \n",
    "                   (x_min_px, y_min_px - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # CROP the detected plate region\n",
    "        cropped_plate = image[y_min_px:y_max_px, x_min_px:x_max_px]\n",
    "        \n",
    "        # Save or process the cropped plate\n",
    "        # cv2.imwrite(f'plate_{class_name}_{i}.jpg', cropped_plate)\n",
    "        # Send cropped_plate to classification model for further processing\n",
    "\n",
    "# Display result\n",
    "cv2.imshow('Detections', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference_code)\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
