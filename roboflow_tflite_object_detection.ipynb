{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roboflow TFLite Object Detection - DetectionPlate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91661081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2114d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IS_COLAB = True\n",
    "except ImportError:  # pragma: no cover\n",
    "    IS_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0936192",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    BASE_DIR = Path('/content')\n",
    "else:\n",
    "    BASE_DIR = Path('/home/manager/Desktop/training_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUARD: Se estamos dentro de models/research, volta para BASE_DIR\n",
    "current_dir = Path.cwd()\n",
    "if 'models/research' in str(current_dir):\n",
    "    os.chdir(str(BASE_DIR))\n",
    "    print(f\"🔄 Voltando para BASE_DIR: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_DIR = BASE_DIR / 'models' / 'research'\n",
    "DATA_ROOT = BASE_DIR / 'data'\n",
    "TEST_IMAGES_SRC = BASE_DIR / 'test' / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Verificando dependências...\")\n",
    "!pip install tensorflow==2.19 protobuf==4.25.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100000\n",
    "num_eval_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"📁 BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"📁 RESEARCH_DIR: {RESEARCH_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c957c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'ssd_mobilenet_v2'\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590661ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "import numpy as np\n",
    "import six.moves.urllib as urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(str(BASE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (BASE_DIR / 'models').exists():\n",
    "    print(\"📥 Clonando TensorFlow models...\")\n",
    "    !git clone --quiet https://github.com/tensorflow/models.git\n",
    "else:\n",
    "    print(\"✅ TensorFlow models já existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📦 Instalando dependências do sistema...\")\n",
    "!pip install tf_slim -q\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk 2>/dev/null || true\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "!pip install -q pycocotools\n",
    "!pip install lvis==0.5.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RESEARCH_DIR / 'object_detection').exists():\n",
    "    print(f\"✅ TensorFlow Object Detection já existe em {RESEARCH_DIR}\")\n",
    "    if not (RESEARCH_DIR / 'object_detection' / 'protos' / 'string_int_label_map_pb2.py').exists():\n",
    "        print(\"🔧 Compilando protos...\")\n",
    "        os.chdir(str(RESEARCH_DIR))\n",
    "        !protoc object_detection/protos/*.proto --python_out=.\n",
    "        os.chdir(str(BASE_DIR))\n",
    "    else:\n",
    "        print(\"✅ Protos já compilados\")\n",
    "else:\n",
    "    print(\"⚠️  TensorFlow Object Detection não encontrado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pythonpath_extra = f\"{str(RESEARCH_DIR)}:{str(RESEARCH_DIR / 'slim')}\"\n",
    "existing_pythonpath = os.environ.get('PYTHONPATH')\n",
    "os.environ['PYTHONPATH'] = (\n",
    "    f\"{existing_pythonpath}:{pythonpath_extra}\" if existing_pythonpath else pythonpath_extra\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📦 Instalando Roboflow...\")\n",
    "!pip install roboflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (DATA_ROOT / 'train' / 'plates.tfrecord').exists() and (DATA_ROOT / 'test' / 'plates.tfrecord').exists():\n",
    "    print(\"✅ Dataset TFRecord já existe, pulando download...\")\n",
    "    dataset_root = DATA_ROOT\n",
    "else:\n",
    "    print(\"📥 Baixando dataset Roboflow...\")\n",
    "    rf = Roboflow(api_key=\"SDfnuMydLG5k2Nq7dlny\")\n",
    "    project = rf.workspace(\"olhodeaguia\").project(\"detectionplate-soevy\")\n",
    "    version = project.version(11)\n",
    "    dataset = version.download(\"tfrecord\", location=str(BASE_DIR / 'train'))\n",
    "    print(f\"✅ Dataset baixado em: {dataset.location}\")\n",
    "    dataset_root = Path(dataset.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65abb77",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_dest_dir = DATA_ROOT / 'train'\n",
    "test_dest_dir = DATA_ROOT / 'test'\n",
    "train_dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_dest_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d1497",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _find_tfrecord(root: Path, subset: str) -> Path:\n",
    "    subset_aliases = {\n",
    "        'train': {'train', 'training'},\n",
    "        'test': {'test', 'testing'},\n",
    "        'val': {'val', 'valid', 'validation'}\n",
    "    }\n",
    "    aliases = subset_aliases.get(subset, {subset})\n",
    "    candidates = []\n",
    "    for path in root.rglob('*.tfrecord'):\n",
    "        parts_lower = {part.lower() for part in path.parts}\n",
    "        stem_lower = path.stem.lower()\n",
    "        if parts_lower & aliases or any(alias in stem_lower for alias in aliases):\n",
    "            candidates.append(path)\n",
    "    if not candidates:\n",
    "        candidates = list(root.rglob('*.tfrecord'))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No TFRecord files found in {root}\")\n",
    "    return candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adc6ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _find_label_map(root: Path) -> Path:\n",
    "    candidates = list(root.rglob('*label_map.pbtxt'))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No label map (.pbtxt) found in {root}\")\n",
    "    # Prefer file inside train subset if available\n",
    "    for candidate in candidates:\n",
    "        if 'train' in {part.lower() for part in candidate.parts}:\n",
    "            return candidate\n",
    "    return candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_record_src = _find_tfrecord(dataset_root, 'train')\n",
    "test_record_src = _find_tfrecord(dataset_root, 'test')\n",
    "if not test_record_src:\n",
    "    test_record_src = _find_tfrecord(dataset_root, 'val')\n",
    "train_label_src = _find_label_map(dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc55cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(train_record_src) != str(train_dest_dir / 'plates.tfrecord'):\n",
    "    shutil.copy(train_record_src, train_dest_dir / 'plates.tfrecord')\n",
    "    print(f\"✅ Copiado: {train_record_src.name}\")\n",
    "else:\n",
    "    print(f\"✅ Train TFRecord já está no lugar correto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(train_label_src) != str(train_dest_dir / 'plates_label_map.pbtxt'):\n",
    "    shutil.copy(train_label_src, train_dest_dir / 'plates_label_map.pbtxt')\n",
    "    print(f\"✅ Copiado: {train_label_src.name}\")\n",
    "else:\n",
    "    print(f\"✅ Label map já está no lugar correto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(test_record_src) != str(test_dest_dir / 'plates.tfrecord'):\n",
    "    shutil.copy(test_record_src, test_dest_dir / 'plates.tfrecord')\n",
    "    print(f\"✅ Copiado: {test_record_src.name}\")\n",
    "else:\n",
    "    print(f\"✅ Test TFRecord já está no lugar correto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d14014",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_fname = str(test_dest_dir / 'plates.tfrecord')\n",
    "train_record_fname = str(train_dest_dir / 'plates.tfrecord')\n",
    "label_map_pbtxt_fname = str(train_dest_dir / 'plates_label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(train_record_fname), f'Train TFRecord not found: {train_record_fname}'\n",
    "assert os.path.isfile(test_record_fname), f'Test TFRecord not found: {test_record_fname}'\n",
    "assert os.path.isfile(label_map_pbtxt_fname), f'Label map not found: {label_map_pbtxt_fname}'\n",
    "print(f'✅ Train TFRecord: {train_record_fname}')\n",
    "print(f'✅ Test TFRecord: {test_record_fname}')\n",
    "print(f'✅ Label map: {label_map_pbtxt_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = str(RESEARCH_DIR / 'pretrained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RESEARCH_DIR / 'pretrained_model' / 'model.ckpt.meta').exists():\n",
    "    print(f\"✅ Modelo pré-treinado já existe em {DEST_DIR}\")\n",
    "else:\n",
    "    print(f\"📥 Baixando modelo pré-treinado {MODEL}...\")\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if not (os.path.exists(MODEL_FILE)) or os.path.getsize(MODEL_FILE) < 1000000:\n",
    "                print(f\"  Tentativa {attempt + 1}/{max_retries}...\")\n",
    "                urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "            \n",
    "            tar = tarfile.open(MODEL_FILE)\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "            break\n",
    "        except (EOFError, tarfile.ReadError, urllib.error.URLError) as e:\n",
    "            print(f\"  ❌ Erro ao baixar/extrair: {e}\")\n",
    "            if os.path.exists(MODEL_FILE):\n",
    "                os.remove(MODEL_FILE)\n",
    "            if attempt == max_retries - 1:\n",
    "                raise ValueError(f\"Falha ao baixar modelo após {max_retries} tentativas\")\n",
    "            continue\n",
    "    \n",
    "    os.remove(MODEL_FILE)\n",
    "    if (os.path.exists(DEST_DIR)):\n",
    "        shutil.rmtree(DEST_DIR)\n",
    "    \n",
    "    if os.path.exists(MODEL):\n",
    "        os.rename(MODEL, DEST_DIR)\n",
    "        print(f\"✅ Modelo extraído para {DEST_DIR}\")\n",
    "    else:\n",
    "        print(f\"❌ Error: {MODEL} not found after extraction\")\n",
    "        print(f\"Available files: {os.listdir('.')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b070a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8107e2d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = str(RESEARCH_DIR / 'object_detection' / 'samples' / 'configs' / pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75462d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9cffdd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "\n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46597cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = str(RESEARCH_DIR / 'training')\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee985e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f89e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b7fa5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b296a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {RESEARCH_DIR}/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e4913",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!ls {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe26f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = str(RESEARCH_DIR / 'fine_tuned_model')\n",
    "tflite_directory = str(RESEARCH_DIR / 'fine_tuned_model' / 'tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d39d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186195ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint = tf.train.latest_checkpoint(model_dir)\n",
    "if latest_checkpoint is None:\n",
    "    raise ValueError(f'No checkpoints found in {model_dir}. Run the training cell first to generate model checkpoints.')\n",
    "print(f'Using checkpoint: {latest_checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {str(RESEARCH_DIR)}/object_detection/exporter_main_v2.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --trained_checkpoint_dir={model_dir} \\\n",
    "    --output_directory={output_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {str(RESEARCH_DIR)}/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --trained_checkpoint_dir={model_dir} \\\n",
    "    --output_directory={tflite_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec8f05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!ls {output_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "print(pb_fname)\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_IMAGES_SRC.exists():\n",
    "    shutil.copytree(TEST_IMAGES_SRC, DATA_ROOT.parent / 'test', dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b947b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = pb_fname\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e889b90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!ls {str(BASE_DIR / 'tensorflow-object-detection-faster-rcnn')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f812caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f58b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58514ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e41b0f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c0ac3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e926292",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7fc09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 5\n",
    "for i, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "    if i > count:\n",
    "        break\n",
    "    image = Image.open(image_path)\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert \\\n",
    "  --input_shape=1,192,192,3 \\\n",
    "  --input_arrays=normalized_input_image_tensor \\\n",
    "  --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 \\\n",
    "  --allow_custom_ops \\\n",
    "  --graph_def_file={tflite_directory}/tflite_graph.pb \\\n",
    "  --output_file=\"{str(RESEARCH_DIR)}/fine_tuned_model/final_model.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Change the final TFLite destination here\n",
    "    !cp {str(RESEARCH_DIR)}/fine_tuned_model/final_model.tflite \"/content/drive/My Drive/\"\n",
    "else:\n",
    "    print(f\"✅ TFLite model saved to: {str(RESEARCH_DIR)}/fine_tuned_model/final_model.tflite\")\n",
    "    print(f\"📁 Copy it manually from {str(RESEARCH_DIR)}/fine_tuned_model/ to your desired location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f25706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📦 COMPACTANDO ARTEFATOS DE TREINAMENTO...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_filename = f\"training_artifacts_{timestamp}.zip\"\n",
    "zip_path = BASE_DIR / zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3399ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_to_backup = [\n",
    "    RESEARCH_DIR / 'training',\n",
    "    RESEARCH_DIR / 'fine_tuned_model',\n",
    "    DATA_ROOT,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e037c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for artifact_dir in artifacts_to_backup:\n",
    "        if artifact_dir.exists():\n",
    "            print(f\"  ➕ Adicionando {artifact_dir.name}...\")\n",
    "            for root, dirs, files in os.walk(artifact_dir):\n",
    "                for file in files:\n",
    "                    file_path = Path(root) / file\n",
    "                    arcname = file_path.relative_to(BASE_DIR)\n",
    "                    zipf.write(file_path, arcname)\n",
    "        else:\n",
    "            print(f\"  ⚠️  {artifact_dir.name} não encontrado, pulando...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"\\n✅ Arquivo compactado: {zip_filename}\")\n",
    "print(f\"📊 Tamanho: {zip_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e541481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    print(\"\\n📥 Iniciando download do Colab...\")\n",
    "    from google.colab import files\n",
    "    files.download(str(zip_path))\n",
    "    print(\"✅ Download concluído!\")\n",
    "else:\n",
    "    print(f\"\\n📁 Arquivo salvo em: {zip_path}\")\n",
    "    print(\"💾 Copie manualmente para seu computador ou nuvem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65533630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Your TFLite file is now in your Drive as \"final_model.tflite\", ready to use with your project on-device! For specific device tutorials, check out the official TensorFlow Lite [Android Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android), [iOS Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios), or [Raspberry Pi Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi). [link text](https://)\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
